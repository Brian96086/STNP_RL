2023-03-06 03:19:37,089 - utils.agents.Base_Agent - INFO - 0 -- STNP_reward_env
2023-03-06 03:19:37,089 - utils.agents.Base_Agent - INFO - 1 -- DISCRETE
2023-03-06 03:19:37,089 - utils.agents.Base_Agent - INFO - 2 -- 270
2023-03-06 03:19:37,089 - utils.agents.Base_Agent - INFO - 3 -- None
2023-03-06 03:19:37,090 - utils.agents.Base_Agent - INFO - 4 -- 100
2023-03-06 03:19:37,090 - utils.agents.Base_Agent - INFO - 5 -- {'learning_rate': 0.001, 'batch_size': 1, 'buffer_size': 40000, 'epsilon': 0.95, 'epsilon_decay_rate_denominator': 1, 'discount_rate': 0.99, 'tau': 0.01, 'alpha_prioritised_replay': 0.6, 'beta_prioritised_replay': 0.1, 'incremental_td_error': 1e-08, 'update_every_n_steps': 20, 'linear_hidden_units': [30, 15], 'final_layer_activation': 'None', 'batch_norm': False, 'gradient_clipping_norm': 0.7, 'learning_iterations': 40, 'clip_rewards': False}
2023-03-06 03:19:37,090 - utils.agents.Base_Agent - INFO - 6 -- inf
2023-03-06 03:19:37,090 - utils.agents.Base_Agent - INFO - 7 -- 100
2023-03-06 03:19:37,090 - utils.agents.Base_Agent - INFO - 8 -- cpu
2023-03-06 03:19:37,137 - utils.agents.Base_Agent - INFO - Reseting game -- New start state tensor([  3.6000,   0.4500,   0.8980,  ..., 102.0000, 108.0000, 202.0000],
       grad_fn=<CatBackward>)
2023-03-06 03:19:37,149 - utils.agents.Base_Agent - INFO - Q values tensor([[-0.2424],
        [ 0.0953],
        [ 0.0373],
        [-0.3838],
        [-0.4514],
        [-0.1957],
        [-0.4327],
        [ 0.6183],
        [-0.3004],
        [ 0.6792],
        [ 0.3093],
        [ 0.1702],
        [ 0.3741],
        [-0.5736],
        [ 0.8216],
        [ 0.2018],
        [ 0.0410],
        [ 0.0981],
        [-0.0753],
        [-0.2897],
        [ 0.0788],
        [ 0.1441],
        [ 0.1966],
        [-0.0188],
        [ 0.0383],
        [ 0.0505],
        [-0.0906],
        [-0.2472],
        [ 0.7236],
        [-0.6665],
        [-0.5252],
        [ 0.3327],
        [ 0.4911],
        [-0.2445],
        [ 0.6819],
        [-0.4844],
        [ 0.5390],
        [-0.8251],
        [ 1.1674],
        [-0.1393],
        [ 0.1821],
        [-0.0579],
        [ 0.4468],
        [ 0.4660],
        [-0.4482],
        [ 0.9880],
        [-0.4590],
        [-0.2666],
        [-0.3481],
        [-0.2783],
        [-0.0000],
        [ 0.5191],
        [-0.3762],
        [ 0.6745],
        [ 0.3771],
        [ 0.2506],
        [-0.4636],
        [-0.7751],
        [-0.9297],
        [-0.1465],
        [-0.4327],
        [ 1.2196],
        [-0.1431],
        [ 0.5331],
        [ 0.2741],
        [ 0.0099],
        [ 0.2796],
        [-0.9953],
        [ 0.4106],
        [-0.1582],
        [-0.4810],
        [-0.2056],
        [ 0.2613],
        [ 0.3127],
        [-0.5425],
        [ 0.0815],
        [-0.4209],
        [-0.8487],
        [ 0.5853],
        [ 1.1982],
        [ 0.2487],
        [ 0.3927],
        [-0.1140],
        [-0.3009],
        [-0.4739],
        [ 0.1076],
        [-0.4431],
        [ 0.5534],
        [ 0.0499],
        [-0.8816],
        [ 0.6376],
        [-0.0434],
        [ 0.2417],
        [-0.2074],
        [-0.7291],
        [ 1.0034],
        [ 1.3931],
        [-0.4165],
        [ 0.2814],
        [-0.1556],
        [-0.4152],
        [-0.0542],
        [ 0.1898],
        [ 1.1565],
        [-0.1470],
        [-0.6931],
        [ 0.6797],
        [ 0.6661],
        [-0.1426],
        [ 0.6706],
        [ 0.0235],
        [-1.0067],
        [-0.7654],
        [ 0.3871],
        [-0.1968],
        [ 0.6108],
        [-0.4208],
        [ 0.3842],
        [-0.6614],
        [-0.3298],
        [ 0.0464],
        [ 0.3842],
        [ 1.2437],
        [ 0.0954],
        [-0.5288],
        [-0.3442],
        [-0.6403],
        [ 0.6814],
        [ 0.0742],
        [-0.1650],
        [-0.1416],
        [-1.3875],
        [-0.1024],
        [-0.6006],
        [ 0.5828],
        [-0.6094],
        [-0.1375],
        [-0.6575],
        [ 0.3155],
        [-0.0797],
        [ 0.5477],
        [ 0.0960],
        [ 0.0951],
        [-0.4306],
        [-0.6671],
        [-0.1037],
        [-0.7003],
        [ 0.2095],
        [ 0.1323],
        [-0.1880],
        [ 0.1506],
        [-0.5982],
        [-0.2579],
        [-0.6281],
        [-0.2839],
        [ 0.7667],
        [ 0.2972],
        [-1.3054],
        [ 0.1923],
        [ 0.3903],
        [ 0.1745],
        [ 0.0517],
        [ 0.2785],
        [ 0.2077],
        [-0.0472],
        [ 0.3721],
        [-0.0564],
        [-0.8468],
        [-1.4722],
        [-0.1264],
        [ 0.3178],
        [ 0.5151],
        [ 0.3344],
        [ 0.0374],
        [ 0.0882],
        [ 0.6734],
        [ 0.0159],
        [-0.0954],
        [-0.2658],
        [ 0.3228],
        [ 0.4329],
        [-0.1788],
        [-0.9943],
        [ 0.3245],
        [ 0.3044],
        [ 1.1296],
        [ 1.1705],
        [-0.1062],
        [-0.4462],
        [-0.2504],
        [-0.8244],
        [-1.1276],
        [-1.0780],
        [-0.1760],
        [ 0.5323],
        [ 0.2741],
        [-0.2928],
        [-0.3894],
        [-0.8650],
        [ 0.0339],
        [-0.5930],
        [ 0.5230],
        [-0.1386],
        [ 0.4180],
        [ 0.4501],
        [-0.5732],
        [-0.4000],
        [ 0.1148],
        [ 0.1025],
        [ 0.2563],
        [-0.3391],
        [-0.0543],
        [-1.3788],
        [ 0.8788],
        [ 0.1731],
        [ 0.2512],
        [-0.0000],
        [ 0.2864],
        [ 0.8854],
        [ 0.6062],
        [-0.5701],
        [ 0.3914],
        [ 0.8824],
        [ 0.6020],
        [ 0.8527],
        [ 0.6070],
        [ 0.8694],
        [-0.5980],
        [ 0.8825],
        [ 0.0000],
        [-0.3552],
        [-0.0900],
        [-0.1666],
        [-0.4669],
        [-0.5550],
        [-0.4356],
        [-0.0146],
        [-0.9786],
        [ 1.0901],
        [ 0.6438],
        [ 0.2585],
        [-0.1303],
        [ 0.2127],
        [ 0.4128],
        [ 0.2033],
        [ 0.4587],
        [ 0.2009],
        [ 0.0000],
        [-0.6288],
        [-0.0215],
        [-0.3819],
        [ 0.2626],
        [ 0.5774],
        [ 0.6496],
        [-0.5418],
        [-1.1899],
        [-0.4132],
        [-1.2565],
        [-0.4867],
        [-0.1091],
        [-0.2886],
        [ 0.0288],
        [-0.4743],
        [-0.6269],
        [ 0.5887],
        [-0.4414],
        [ 0.5174],
        [ 0.0280],
        [ 0.0909],
        [-0.4459]], dtype=torch.float64) -- Action chosen 96
